import torch
import torch.nn.functional as F
import typing
from typing import Optional, List, Union, Dict, Tuple
from collections import namedtuple
import math
import functools





def discriminator_loss(
    disc_real_outputs: List[torch.Tensor], disc_generated_outputs: List[torch.Tensor]
) -> Tuple[torch.Tensor, List[torch.Tensor], List[torch.Tensor]]:

    loss = 0
    r_losses = []
    g_losses = []
    for dr, dg in zip(disc_real_outputs, disc_generated_outputs):
        r_loss = torch.mean((1 - dr) ** 2)
        g_loss = torch.mean(dg**2)
        loss += r_loss + g_loss
        r_losses.append(r_loss.item())
        g_losses.append(g_loss.item())

    return loss, r_losses, g_losses



def generator_loss(
    disc_outputs: List[torch.Tensor],
) -> Tuple[torch.Tensor, List[torch.Tensor]]:

    loss = 0
    gen_losses = []
    for dg in disc_outputs:
        l = torch.mean((1 - dg) ** 2)
        gen_losses.append(l)
        loss += l

    return loss, gen_losses



def kl_loss(z_p, logs_q, m_p, logs_p, z_mask):
    """
    z_p, logs_q: [b, h, t_t]
    m_p, logs_p: [b, h, t_t]
    """
    z_p = z_p.float()
    logs_q = logs_q.float()
    m_p = m_p.float()
    logs_p = logs_p.float()
    z_mask = z_mask.float()

    kl = logs_p - logs_q - 0.5
    kl += 0.5 * ((z_p - m_p) ** 2) * torch.exp(-2.0 * logs_p)
    kl = torch.sum(kl * z_mask)
    l = kl / torch.sum(z_mask)
    return l



def feature_loss(
    fmap_r: List[List[torch.Tensor]], fmap_g: List[List[torch.Tensor]]
) -> torch.Tensor:

    loss = 0
    for dr, dg in zip(fmap_r, fmap_g):
        for rl, gl in zip(dr, dg):
            loss += torch.mean(torch.abs(rl - gl))

    return loss * 2  # This equates to lambda=2.0 for the feature matching loss





# OLD
#def discriminator_loss(disc_real_outputs, disc_generated_outputs):
#    loss = 0
#    r_losses = []
#    g_losses = []
#    for dr, dg in zip(disc_real_outputs, disc_generated_outputs):
#        dr = dr.float()
#        dg = dg.float()
#        r_loss = torch.mean((1 - dr) ** 2)
#        g_loss = torch.mean(dg**2)
#        loss += r_loss + g_loss
#        r_losses.append(r_loss.item())
#        g_losses.append(g_loss.item())
#
#    return loss, r_losses, g_losses



#def generator_loss(disc_outputs):
#    loss = 0
#    gen_losses = []
#    for dg in disc_outputs:
#        dg = dg.float()
#        l = torch.mean((1 - dg) ** 2)
#        gen_losses.append(l)
#        loss += l
#
#    return loss, gen_losses



def generator_loss_sp(disc_outputs, mel_generated, silence_threshold=-67.0, silence_penalty_weight=0.1, silence_threshold_ratio=0.9):
    """
    Calculate the generator's loss, including penalties for excessive silence.

    Parameters:
    - disc_outputs: Outputs from the discriminator (used for adversarial loss)
    - mel_generated: The mel spectrograms generated by the generator (y_hat_mel)
    - silence_threshold: The dB threshold below which a region is considered silence (default: -67 dB)
    - silence_penalty_weight: The weight of the penalty for generating excessive silence (default: 0.1)
    - silence_threshold_ratio: The ratio of silence in the generated sample above which penalty will be applied (default: 0.9 for 90%)

    Returns:
    - loss: The total loss including adversarial and silence penalty
    - gen_losses: List of individual generator losses (used for monitoring)
    """
    loss = 0
    gen_losses = []
    
    # Adversarial loss (same as original)
    for dg in disc_outputs:
        dg = dg.float()
        l = torch.mean((1 - dg) ** 2)
        gen_losses.append(l)
        loss += l

    # Silence detection
    silence_penalty = 0.0
    for mel in mel_generated:
        # Calculate the proportion of silence in the mel spectrogram (below silence threshold)
        silent_frames = mel < silence_threshold  # Binary mask where silent values are True (below threshold)
        silence_ratio = silent_frames.float().mean()  # Mean across all frames in the mel spectrogram

        # Apply penalty if silence ratio exceeds the threshold ratio (e.g., > 90% silent)
        if silence_ratio > silence_threshold_ratio:
            silence_penalty += silence_ratio  # Optionally scale the penalty by the silence ratio

    # Apply the silence penalty only if there was any sample with excessive silence
    if silence_penalty > 0.0:
        loss += silence_penalty_weight * silence_penalty

    return loss, gen_losses


# OLD
#def feature_loss(fmap_r, fmap_g):
#    loss = 0
#    for dr, dg in zip(fmap_r, fmap_g):
#        for rl, gl in zip(dr, dg):
#            rl = rl.float().detach()
#            gl = gl.float()
#            loss += torch.mean(torch.abs(rl - gl))
#
#    return loss * 2


# less biased towards deeper layers

def multi_scale_feature_loss_log(fmap_r, fmap_g):
    loss = 0
    num_scales = len(fmap_r)  # Number of scales (layers)
    
    # Iterate through the feature maps for real (fmap_r) and generated (fmap_g) audio
    for i, (dr, dg) in enumerate(zip(fmap_r, fmap_g)):
        scale_weight = torch.log(torch.tensor(num_scales - i, dtype=torch.float32))  # Logarithmic scaling
        
        # Iterate through the feature maps at each layer
        for rl, gl in zip(dr, dg):
            rl = rl.float().detach()  # Detach real feature maps
            gl = gl.float()  # Convert generated feature maps to float
            loss += torch.mean(torch.abs(rl - gl)) * scale_weight  # Apply the log-scaled weight
    
    return loss * 2  # You can adjust the factor as necessary



#def multi_scale_feature_loss(fmap_r, fmap_g):
#    loss = 0
#    for dr, dg in zip(fmap_r, fmap_g):
#        for rl, gl in zip(dr, dg):
#            rl = rl.float().detach()
#            gl = gl.float()
#            # Add multi-scale weighting, giving importance to deeper layers
#            loss += torch.mean(torch.abs(rl - gl)) * (2 ** (len(fmap_r) - len(dr)))
#    return loss * 2



#def zero_mean_loss(generated_waveform, lambda_zero_mean=0.1):
#    """
#    Zero-Mean Loss to penalize non-zero DC offset in the generated waveform.
#    
#    Args:
#        generated_waveform (Tensor): The generated waveform output by the generator.
#        lambda_zero_mean (float): Scaling factor for the zero-mean loss (default is 0.1).
#        
#    Returns:
#        Tensor: A scalar loss value that penalizes the non-zero mean of the waveform.
#    """
#    # Calculate the mean of the generated waveform
#    mean_waveform = torch.mean(generated_waveform)
#    
#    # Penalize the square of the mean value (L2 norm), encouraging the mean to be zero
#    loss = torch.square(mean_waveform)  
#
#    # Scale the loss by lambda_zero_mean
#    loss *= lambda_zero_mean
#
#    return loss * 1


# EXPERIMENTAL and NOT TESTED. If you wanna try it, uncomment this one and comment the "generator_loss_sp" function at the top, below normal generator_loss.

#def generator_loss_sp(disc_outputs, mel_generated, silence_threshold=-67.0, silence_penalty_weight=0.1, silence_threshold_ratio=0.9, max_silence_penalty=1.0):
#    """
#    Calculate the generator's loss, including penalties for excessive silence, but with soft and selective penalties to avoid associating good samples with collapse.
#
#    Parameters:
#    - disc_outputs: Outputs from the discriminator (used for adversarial loss)
#    - mel_generated: The mel spectrograms generated by the generator (y_hat_mel)
#    - silence_threshold: The dB threshold below which a region is considered silence (default: -67 dB)
#    - silence_penalty_weight: The weight of the penalty for generating excessive silence (default: 0.1)
#    - silence_threshold_ratio: The ratio of silence in the generated sample above which penalty will be applied (default: 0.9 for 90%)
#    - max_silence_penalty: The maximum penalty allowed for a silent sample (default: 1.0)
#
#    Returns:
#    - loss: The total loss including adversarial and softened silence penalty
#    - gen_losses: List of individual generator losses (used for monitoring)
#    """
#    loss = 0
#    gen_losses = []
#    
#    # Adversarial loss (same as original)
#    for dg in disc_outputs:
#        dg = dg.float()
#        l = torch.mean((1 - dg) ** 2)
#        gen_losses.append(l)
#        loss += l
#
#    # Silence detection (softened penalty to avoid associating good samples with collapse)
#    silence_penalty = 0.0
#    num_samples = len(mel_generated)
#    silent_sample_count = 0
#
#    for mel in mel_generated:
#        # Calculate the proportion of silence in the mel spectrogram (below silence threshold)
#        silent_frames = mel < silence_threshold  # Binary mask where silent values are True (below threshold)
#        silence_ratio = silent_frames.float().mean()  # Mean across all frames in the mel spectrogram
#
#        # If silence ratio exceeds the threshold ratio (e.g., > 90% silent), apply a softened penalty
#        if silence_ratio > silence_threshold_ratio:
#            silent_sample_count += 1
#            # Scale penalty based on the amount of silence (more silence = higher penalty)
#            silence_penalty += silence_penalty_weight * silence_ratio
#
#    # Apply the softened penalty if there are any silent samples
#    if silent_sample_count > 0:
#        # Scale the total penalty by the number of silent samples in the batch
#        silence_penalty /= silent_sample_count  # Average penalty across silent samples
#        # Limit the max penalty so it's not too extreme
#        silence_penalty = min(silence_penalty, max_silence_penalty)
#        loss += silence_penalty
#
#    return loss, gen_losses
